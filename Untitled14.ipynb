{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a1eb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting BeautifulSoup\n",
      "  Downloading BeautifulSoup-3.2.2.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [7 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-install-z76mi_4v\\beautifulsoup_6d1d99c4a2fa4288bfd907503b7ef042\\setup.py\", line 3\n",
      "      \"You're trying to run a very old release of Beautiful Soup under Python 3. This will not work.\"<>\"Please use Beautiful Soup 4, available through the pip package 'beautifulsoup4'.\"\n",
      "                                                                                                     ^^\n",
      "  SyntaxError: invalid syntax\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d958f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e3d7a54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data=requests.get(\"https://practice.geeksforgeeks.org/courses\")\n",
    "if raw_data.status_code == 200:\n",
    "    soup = BeautifulSoup(raw_data.content, 'html.parser')\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ea4ef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses GeeksforGeeks | Interactive LIVE and Self-Paced CoursesCoursesTutorialsJobsPracticeContestsData StructureJavaPythonHTMLInterview PreparationTrending NowData StructuresAlgorithmsFoundational CoursesData SciencePractice ProblemPythonMachine LearningJavaScriptJavaC C++ReactJSNodeJSCompetitive ProgrammingAptitudePuzzlesProjectsWeb DevelopmentGeeksforGeeks CoursesInteractive LIVE & Self-Paced CoursesA-143, 9th Floor, Sovereign Corporate Tower, Sector-136, Noida, Uttar Pradesh - 201305feedback@geeksforgeeks.orgCompanyAbout UsLegalCareersIn MediaContact UsAdvertise with usCampus Training ProgramExploreJob-A-Thon Hiring ChallengeHack-A-ThonGfG Weekly ContestOffline Classes (Delhi/NCR)DSA in JAVA/C++Master System DesignMaster CPLanguagesPythonJavaC++PHPGoLangSQLR LanguageAndroid TutorialDSA ConceptsData StructuresArraysStringsLinked ListAlgorithmsSearchingSortingMathematicalDynamic ProgrammingDSA RoadmapsDSA for BeginnersBasic DSA Coding ProblemsDSA Roadmap by Sandeep JainDSA with JavaScriptTop 100 DSA Interview ProblemsAll Cheat SheetsWeb DevelopmentHTMLCSSJavaScriptBootstrapReactJSAngularJSNodeJSExpress.jsLodashComputer ScienceGATE CS NotesOperating SystemsComputer NetworkDatabase Management SystemSoftware EngineeringDigital Logic DesignEngineering MathsPythonPython Programming ExamplesDjango TutorialPython ProjectsPython TkinterOpenCV Python TutorialPython Interview QuestionData Science & MLData Science With PythonData Science For BeginnerMachine Learning TutorialMaths For Machine LearningPandas TutorialNumPy TutorialNLP TutorialDeep Learning TutorialDevOpsGitAWSDockerKubernetesAzureGCPCompetitive ProgrammingTop DSA for CPTop 50 Tree ProblemsTop 50 Graph ProblemsTop 50 Array ProblemsTop 50 String ProblemsTop 50 DP ProblemsTop 15 Websites for CPSystem DesignWhat is System DesignMonolithic and Distributed SDScalability in SDDatabases in SDHigh Level Design or HLDLow Level Design or LLDTop SD Interview QuestionsInterview CornerCompany Wise PreparationPreparation for SDEExperienced InterviewsInternship InterviewsCompetitive ProgrammingAptitude PreparationGfG SchoolCBSE Notes for Class 8CBSE Notes for Class 9CBSE Notes for Class 10CBSE Notes for Class 11CBSE Notes for Class 12English GrammarCommerceAccountancyBusiness StudiesEconomicsHuman Resource Management (HRM)ManagementIncome TaxFinanceStatistics for EconomicsUPSCPolity NotesGeography NotesHistory NotesScience and Technology NotesEconomics NotesImportant Topics in EthicsUPSC Previous Year PapersSSC/ BANKINGSSC CGL SyllabusSBI PO SyllabusSBI Clerk SyllabusIBPS PO SyllabusIBPS Clerk SyllabusAptitude QuestionsSSC CGL Practice PapersWrite & EarnWrite an ArticleImprove an ArticlePick Topics to WriteWrite Interview ExperienceInternships@geeksforgeeks, All rights reserved\n"
     ]
    }
   ],
   "source": [
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4088108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Courses GeeksforGeeks | Interactive LIVE and Self-Paced Courses</title>\n"
     ]
    }
   ],
   "source": [
    "res=soup.title\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9ea29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08c20dc2",
   "metadata": {},
   "source": [
    "# extract name class and create dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8deea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "title_elements = soup.select(\".a-size-medium\")\n",
    "for element in title_elements:\n",
    "    titles.append(element.text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab4c5ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b85b527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Details]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2824665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = soup.select(\"._30jeq3\") \n",
    "price = [] \n",
    "for i in x : \n",
    "    price.append((i.contents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41ec12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price = pd.DataFrame(price , columns = ['Price']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "647665eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05e1d9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve the webpage.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of Amazon Best Sellers in Computers & Accessories\n",
    "url = \"https://www.amazon.com/Motorola-Stylus-Battery-Unlocked-Emerald/dp/B0BFYRV4CD/ref=sr_1_1?crid=2MYR7H2NTPP2A&keywords=mobile%2Bphones&qid=1696733969&sprefix=mobile%2Bphones%2Caps%2C1071&sr=8-1&th=1\"\n",
    "\n",
    "\n",
    "raw_data = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if raw_data.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(raw_data.content, 'html.parser')\n",
    "\n",
    "    # Extract product titles\n",
    "    titles = []\n",
    "    title_elements = soup.select(\".product-title\")\n",
    "    for element in title_elements:\n",
    "        titles.append(element.text.strip())\n",
    "\n",
    "    # Extract product prices\n",
    "    prices = []\n",
    "    price_elements = soup.select(\".a-price-symbol\")\n",
    "    for element in price_elements:\n",
    "        prices.append(element.text.strip())\n",
    "\n",
    "    # Create DataFrames\n",
    "    df_title = pd.DataFrame(titles, columns=['Product Title'])\n",
    "    df_price = pd.DataFrame(prices, columns=['Product Price'])\n",
    "\n",
    "    # Combine the DataFrames if needed\n",
    "    final_df = pd.concat([df_title, df_price], axis=1)\n",
    "\n",
    "    # Print or save the final DataFrame\n",
    "    print(final_df)\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage.\")\n",
    "\n",
    "# Close the request session\n",
    "raw_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2e4c484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve the webpage.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of Amazon Best Sellers in Computers & Accessories\n",
    "url = \"https://www.amazon.com/Best-Sellers-Computers-Accessories/zgbs/pc\"\n",
    "\n",
    "\n",
    "raw_data = requests.get(url, )\n",
    "\n",
    "# Check if the request was successful\n",
    "if raw_data.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(raw_data.content, 'html.parser')\n",
    "\n",
    "    # Extract product titles\n",
    "    titles = []\n",
    "    title_elements = soup.select(\".a-text-normal\")\n",
    "    for element in title_elements:\n",
    "        titles.append(element.text.strip())\n",
    "\n",
    "    # Extract product prices\n",
    "    prices = []\n",
    "    price_elements = soup.select(\".a-price .a-offscreen\")\n",
    "    for element in price_elements:\n",
    "        prices.append(element.text.strip())\n",
    "\n",
    "    # Create DataFrames\n",
    "    df_title = pd.DataFrame(titles, columns=['Product Title'])\n",
    "    df_price = pd.DataFrame(prices, columns=['Product Price'])\n",
    "\n",
    "    # Combine the DataFrames if needed\n",
    "    final_df = pd.concat([df_title, df_price], axis=1)\n",
    "\n",
    "    # Print or save the final DataFrame\n",
    "    print(final_df)\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage.\")\n",
    "\n",
    "# Close the request session\n",
    "raw_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08ea750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Product Title, Product Price]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of Amazon Best Sellers in Computers & Accessories\n",
    "url = \"https://www.amazon.com/Motorola-Stylus-Battery-Unlocked-Emerald/dp/B0BFYRV4CD/ref=sr_1_1?crid=2MYR7H2NTPP2A&keywords=mobile%2Bphones&qid=1696733969&sprefix=mobile%2Bphones%2Caps%2C1071&sr=8-1&th=1\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36\"\n",
    "}\n",
    "\n",
    "raw_data = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if raw_data.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(raw_data.content, 'html.parser')\n",
    "\n",
    "    # Extract product titles\n",
    "    titles = []\n",
    "    title_elements = soup.select(\".a-size-large\")\n",
    "    for element in title_elements:\n",
    "        titles.append(element.text.strip())\n",
    "\n",
    "    # Extract product prices\n",
    "    prices = []\n",
    "    price_elements = soup.select(\".a-price \")\n",
    "    for element in price_elements:\n",
    "        prices.append(element.text.strip())\n",
    "\n",
    "    # Create DataFrames\n",
    "    df_title = pd.DataFrame(titles, columns=['Product Title'])\n",
    "    df_price = pd.DataFrame(prices, columns=['Product Price'])\n",
    "\n",
    "    # Combine the DataFrames if needed\n",
    "    final_df = pd.concat([df_title, df_price], axis=1)\n",
    "\n",
    "    # Print or save the final DataFrame\n",
    "    print(final_df)\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage.\")\n",
    "\n",
    "# Close the request session\n",
    "raw_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4563bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
